# Ralph Configuration Example
# Copy this file to .ralph/config.yaml in your project root

# Maximum number of development iterations before stopping
maxIterations: 10

# Base branch for pull requests
baseBranch: main

# LLM configuration is now managed by OpenCode
# Configure your LLM provider/model with: opencode config set model provider/model
# Examples:
#   opencode config set model deepseek/deepseek-chat
#   opencode config set model anthropic/claude-3-5-sonnet-20241022
#   opencode config set model openai/gpt-4

# Commands to run once before starting services and the iteration loop
# Useful for compilation, code generation, dependency setup, or any other preparation
before:
  # Example: Compile the application
  - name: compile-app
    command: go
    args: [build, -o, bin/app, ./cmd/app]

  # Example: Generate code
  - name: generate-proto
    command: protoc
    args: [--go_out=., --go_opt=paths=source_relative, proto/*.proto]

# Services to start/stop during development
# Each service can optionally specify a port for health checking
services:
  # Example: PostgreSQL database via Podman Compose
  - name: database
    command: podman
    args: [compose, up, -d, postgres]
    port: 5432 # Optional: port for health checking

  # Example: Redis cache via Podman Compose
  - name: redis
    command: podman
    args: [compose, up, -d, redis]
    port: 6379

  # Example: Development server (Node.js)
  - name: api-server
    command: npm
    args: [run, dev]
    port: 3000

  # Example: Background worker (no port for health check)
  - name: worker
    command: python
    args: [worker.py]
    # No port specified = no health check, just verify process is running

  # Example: Frontend development server
  - name: frontend
    command: npm
    args: [run, dev:frontend]
    port: 8080
# Notes:
# Before Commands:
# - Before commands are executed once at the start of a project (not per iteration)
# - They run sequentially and must complete successfully before proceeding
# - Useful for compilation, code generation, dependency setup, or other preparation
#
# Services:
# - Services are started in order before AI agent execution
# - Health checks wait for TCP ports to respond (if port is specified)
# - Services are stopped gracefully (SIGTERM) after execution
# - If a service fails to start, the command will error
# - Use --no-services flag to skip service management
